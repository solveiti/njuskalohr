#!/bin/bash

# Setup script for Njuskalo Sitemap Store Scraper
# This script installs Chrome browser and Python dependencies

echo "ğŸª Njuskalo Sitemap Store Scraper Setup"
echo "======================================"

# Check if running as root
if [[ $EUID -eq 0 ]]; then
   echo "âŒ Don't run this script as root/sudo"
   exit 1
fi

# Update package lists
echo "ğŸ“¦ Updating package lists..."
sudo apt update

# Install Chrome browser
echo "ğŸŒ Installing Google Chrome..."
if ! command -v google-chrome &> /dev/null; then
    # Download Chrome
    wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
    echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
    sudo apt update
    sudo apt install -y google-chrome-stable
    echo "âœ… Chrome installed successfully"
else
    echo "âœ… Chrome already installed"
fi

# Create virtual environment if it doesn't exist
if [ ! -d ".venv" ]; then
    echo "ğŸ Creating Python virtual environment..."
    python3 -m venv .venv
    echo "âœ… Virtual environment created"
else
    echo "âœ… Virtual environment already exists"
fi

# Activate virtual environment and install dependencies
echo "ğŸ Installing Python dependencies..."
if [ -f "requirements.txt" ]; then
    .venv/bin/pip install --upgrade pip
    .venv/bin/pip install -r requirements.txt
    echo "âœ… Python dependencies installed"
else
    echo "âŒ requirements.txt not found"
    exit 1
fi

# Test installation
echo "ğŸ§ª Testing installation..."
echo "Checking Chrome version:"
google-chrome --version

echo ""
echo "Checking Python packages:"
.venv/bin/pip list | grep -E "(selenium|pandas|openpyxl|requests|lxml|beautifulsoup4)"

echo ""
echo "âœ… Setup complete!"
echo ""
echo "ğŸš€ Usage:"
echo "  Run the scraper with: .venv/bin/python run_scraper.py"
echo "  Or make it executable: chmod +x run_scraper.py && ./run_scraper.py"
echo ""
echo "ğŸ“‹ What this scraper does:"
echo "  1. Downloads sitemap index from njuskalo.hr"
echo "  2. Finds and downloads store-related XML files"
echo "  3. Extracts store URLs (trgovina) from sitemaps"
echo "  4. Visits each store page to scrape information"
echo "  5. Checks for Auto Moto category (categoryId=2)"
echo "  6. Extracts store address and ad counts"
echo "  7. Saves results to Excel file"
echo ""
echo "ğŸš€ To run the scraper:"
echo "   python run_scraper.py"
echo ""
echo "ğŸ“š For more information, see README.md"